{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:06:30.479813Z",
     "iopub.status.busy": "2025-06-30T19:06:30.479329Z",
     "iopub.status.idle": "2025-06-30T19:06:34.029037Z",
     "shell.execute_reply": "2025-06-30T19:06:34.028256Z",
     "shell.execute_reply.started": "2025-06-30T19:06:30.479788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q beautifulsoup4 faiss-cpu scikit-learn sentence-transformers google-generativeai easyocr openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:06:34.030713Z",
     "iopub.status.busy": "2025-06-30T19:06:34.030478Z",
     "iopub.status.idle": "2025-06-30T19:06:46.501655Z",
     "shell.execute_reply": "2025-06-30T19:06:46.501007Z",
     "shell.execute_reply.started": "2025-06-30T19:06:34.030689Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 19:06:39.326923: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751310399.349365     152 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751310399.356137     152 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "from datetime import datetime\n",
    "import google.generativeai as genai\n",
    "from uuid import uuid4\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "import easyocr \n",
    "import whisper\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAG-ekUHZXwJpeHTGKAFyiRD2uKVuYn00\"\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "gemini = genai.GenerativeModel('models/gemini-1.5-flash-latest')\n",
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:14:01.306534Z",
     "iopub.status.busy": "2025-06-30T19:14:01.306211Z",
     "iopub.status.idle": "2025-06-30T19:14:01.339210Z",
     "shell.execute_reply": "2025-06-30T19:14:01.338434Z",
     "shell.execute_reply.started": "2025-06-30T19:14:01.306510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_article_text_body(url):\n",
    "    try:\n",
    "        res = requests.get(url, timeout=10)\n",
    "        res.raise_for_status() \n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "        for script_or_style in soup(['script', 'style']):\n",
    "            script_or_style.decompose()\n",
    "            \n",
    "        main_content_div = soup.find(['article', 'main'], class_=[\n",
    "            'entry-content', 'article-content', 'post-content', 'main-content',\n",
    "            'blog-post-content', 'single-post-content', 'content-area'\n",
    "        ])\n",
    "\n",
    "        if not main_content_div:\n",
    "            main_content_div = soup.find('div', id=['content', 'main', 'bodyContent'])\n",
    "        if not main_content_div:\n",
    "            main_content_div = soup.find('div', class_=['content', 'post', 'article', 'page'])\n",
    "\n",
    "        text_parts = []\n",
    "\n",
    "        page_title = soup.title.string if soup.title else ''\n",
    "        if page_title:\n",
    "            text_parts.append(page_title.strip())\n",
    "\n",
    "        if main_content_div:\n",
    "            full_text = main_content_div.get_text(separator='\\n').strip()\n",
    "        else:\n",
    "            full_text = soup.body.get_text(separator='\\n').strip()\n",
    "\n",
    "        cleaned_lines = [line.strip() for line in full_text.splitlines() if line.strip()]\n",
    "        filtered_lines = []\n",
    "        for line in cleaned_lines:\n",
    "            \n",
    "            if len(line) < 5 and not any(char.isalnum() for char in line): \n",
    "                continue\n",
    "            if \"copyright\" in line.lower() or \"all rights reserved\" in line.lower():\n",
    "                continue \n",
    "\n",
    "            filtered_lines.append(line)\n",
    "\n",
    "        final_text = \"\\n\\n\".join(filtered_lines)\n",
    "        return final_text\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Network error or invalid URL: {e}\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during parsing for {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def get_user_inputs(mode=\"profile\"):\n",
    "    if mode == \"topic\":\n",
    "        prompt_title = \" Provide 1 Topic/Idea for Your New Post:\"\n",
    "        max_posts = 1\n",
    "    else:\n",
    "        prompt_title = \" Paste 3‚Äì5 of your text posts below:\"\n",
    "        max_posts = 5\n",
    "\n",
    "    method = input(f\"Choose Input Type:\\n1. Paste Text\\n2. Upload File\\n3. Enter URL\\n4. Use Infographic Image (from dataset)\\n5. Use Audio Clip (from dataset)\\nEnter choice (1-5): \").strip()\n",
    "    \n",
    "    posts = []\n",
    "    extracted_texts = []\n",
    "\n",
    "    if method == \"1\":  # Paste Text\n",
    "        print(prompt_title)\n",
    "        for i in range(max_posts):\n",
    "            post = input(f\"Post {i+1}: \").strip()\n",
    "            if post:\n",
    "                posts.append(post)\n",
    "            if mode == \"topic\" and posts:\n",
    "                break\n",
    "\n",
    "    elif method == \"2\":  # File\n",
    "        path = input(\"Enter file path: \").strip()\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                lines = [line.strip() for line in f if line.strip()]\n",
    "                posts.extend(lines[:max_posts])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "    elif method == \"3\":  # URL\n",
    "        for i in range(max_posts):\n",
    "            url = input(f\"URL {i+1}: \").strip()\n",
    "            if not url:\n",
    "                continue\n",
    "            print(\" Scraping...\")\n",
    "            text_content = extract_article_text_body(url)\n",
    "            if text_content:\n",
    "                print(\"\\n Extracted Text from URL:\\n\" + \"-\"*50)\n",
    "                print(text_content[:1000] + (\"...\" if len(text_content) > 1000 else \"\"))\n",
    "                print(\"-\"*50)\n",
    "                posts.append(text_content)\n",
    "                extracted_texts.append(text_content)\n",
    "                if mode == \"topic\":\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"‚ùå Couldn‚Äôt extract content from {url}\")\n",
    "\n",
    "    elif method == \"4\":  # Image (Infographic)\n",
    "        print(\" Using image from Kaggle input dataset\")\n",
    "        image_path = input(\"Enter full image path (e.g., /kaggle/input/your-dataset-name/infographic.png): \").strip()\n",
    "        try:\n",
    "            import easyocr\n",
    "            reader = easyocr.Reader(['en'])\n",
    "            ocr_results = reader.readtext(image_path)\n",
    "            extracted_text = \" \".join([text[1] for text in ocr_results])\n",
    "            if extracted_text.strip():\n",
    "                print(\"\\n Extracted Text from Image:\\n\" + \"-\"*50)\n",
    "                print(extracted_text)\n",
    "                print(\"-\"*50)\n",
    "                posts.append(extracted_text)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå OCR Error: {e}\")\n",
    "\n",
    "    elif method == \"5\":  # Audio\n",
    "        print(\" Using audio file from Kaggle input dataset\")\n",
    "        audio_path = input(\"Enter full audio file path (e.g., /kaggle/input/your-dataset-name/audio.mp3): \").strip()\n",
    "        try:\n",
    "            import whisper\n",
    "            model = whisper.load_model(\"base\")\n",
    "            transcription = model.transcribe(audio_path)\n",
    "            if transcription[\"text\"].strip():\n",
    "                print(\"\\n Transcribed Text from Audio:\\n\" + \"-\"*50)\n",
    "                print(transcription[\"text\"])\n",
    "                print(\"-\"*50)\n",
    "                posts.append(transcription[\"text\"])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Audio Transcription Error: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(\"‚ùå Invalid choice.\")\n",
    "\n",
    "    return posts[:max_posts], extracted_texts\n",
    "\n",
    "#voice calibration\n",
    "voice_pairs = [\n",
    "    (\"Cognitive Framing\", \"I like to simplify complexity so people get the ‚Äòaha!‚Äô moment.\", \"I like to explore nuanced topics, even if they‚Äôre a bit messy or open-ended.\"),\n",
    "    (\"Value Communication\", \"I try to give readers something they can immediately apply.\", \"I aim to change how readers think about a topic.\"),\n",
    "    (\"Emotional Tone\", \"I prefer to keep a calm, composed tone in my content.\", \"I‚Äôm okay showing strong opinions and emotional highs/lows.\"),\n",
    "    (\"Communication Texture\", \"I speak in plain, precise language.\", \"I enjoy using analogies, metaphors, or playful phrasing.\"),\n",
    "    (\"Risk Appetite\", \"I prefer to play it safe ‚Äî stay useful, stay relevant.\", \"I‚Äôm okay challenging norms or triggering strong reactions.\"),\n",
    "    (\"Relational Energy\", \"I tend to speak to the audience like a guide or coach.\", \"I like writing more like a peer, friend, or co-explorer.\"),\n",
    "]\n",
    "\n",
    "def get_tone_vector():\n",
    "    tone = {}\n",
    "    for label, a, b in voice_pairs:\n",
    "        print(f\"\\nüéØ {label}:\")\n",
    "        print(f\"A: {a}\\nB: {b}\")\n",
    "        while True:\n",
    "            ans = input(\"Choose A or B: \").strip().upper()\n",
    "            if ans in [\"A\", \"B\"]:\n",
    "                tone[label] = 0.0 if ans == \"A\" else 1.0\n",
    "                break\n",
    "    return tone\n",
    "\n",
    "def get_user_metadata():\n",
    "    niche = input(\"\\nWhat niche do you create content in? \").strip()\n",
    "\n",
    "    goal_options = ['reach', 'sales', 'trust', 'educate', 'thought leadership']\n",
    "    print(\"Select 1‚Äì2 primary content goals:\")\n",
    "    for i, opt in enumerate(goal_options):\n",
    "        print(f\"{i+1}. {opt}\")\n",
    "    selected_goals = input(\"Enter goal numbers (comma-separated): \").strip().split(',')\n",
    "    goals = [goal_options[int(i)-1] for i in selected_goals if i.isdigit() and 0 < int(i) <= len(goal_options)]\n",
    "\n",
    "    arch_options = [\n",
    "        \"The Teacher\", \"The Challenger\", \"The Storyteller\", \"The Visionary\",\n",
    "        \"The Operator\", \"The Curator\", \"The Trend Decoder\", \"The Builder\"\n",
    "    ]\n",
    "    print(\"\\n Select 1‚Äì2 content archetypes:\")\n",
    "    for i, opt in enumerate(arch_options):\n",
    "        print(f\"{i+1}. {opt}\")\n",
    "    selected_archetypes = input(\"Enter archetype numbers: \").strip().split(',')\n",
    "    archetypes = [arch_options[int(i)-1] for i in selected_archetypes if i.isdigit() and 0 < int(i) <= len(arch_options)]\n",
    "\n",
    "    platform = input(\"\\n Primary platform (LinkedIn, Instagram, etc): \").strip().lower()\n",
    "\n",
    "    return {\"niche\": niche, \"goals\": goals, \"platform\": platform, \"archetypes\": archetypes}\n",
    "\n",
    "#LLM summary\n",
    "def generate_llm_summary(posts, tone_vec, metadata):\n",
    "    short_snips = \"\\n\".join([f\"{i+1}. {p[:100]}\" for i, p in enumerate(posts[:3])])\n",
    "\n",
    "    compact_prefs = {\n",
    "        \"Nuanced\": int(tone_vec.get(\"Cognitive Framing\", 0)),\n",
    "        \"Actionable\": int(tone_vec.get(\"Value Communication\", 0) == 0),\n",
    "        \"Emotional\": int(tone_vec.get(\"Emotional Tone\", 0)),\n",
    "        \"Analogies\": int(tone_vec.get(\"Communication Texture\", 0)),\n",
    "        \"Bold\": int(tone_vec.get(\"Risk Appetite\", 0)),\n",
    "        \"Relatable\": int(tone_vec.get(\"Relational Energy\", 0)),\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Summarize the writing style of this creator,posts written by the same person:{short_snips}\n",
    "\n",
    "Using both the posts and this style embedding, summarize the user's writing style with:\n",
    "- Cognitive style (logic-driven vs intuition-driven)\n",
    "- Energy signature (calm, aggressive, witty, etc.)\n",
    "- Lexical patterns (word choice, punctuation)\n",
    "- Narrative identity (e.g., underdog, guide)\n",
    "- Content archetype (educator, motivator, etc.)\n",
    "- Audience intent (clients, recruiters, etc.)\n",
    "\n",
    "Focus on voice, tone, and energy. Conclude with how they typically frame ideas and close posts.\n",
    "Niche: {metadata['niche']}\n",
    "Goals: {metadata['goals']}\n",
    "Archetypes: {metadata['archetypes']}\n",
    "Preferences: {compact_prefs}\n",
    "\"\"\"\n",
    "\n",
    "    return gemini.generate_content(prompt).text.strip()\n",
    "\n",
    "def build_psyprint_dataset(posts, tone_vec, metadata):\n",
    "    if posts and isinstance(posts[0], list):\n",
    "        posts = [item for sublist in posts for item in sublist]\n",
    "\n",
    "    embeddings = encoder.encode(posts, convert_to_numpy=True)\n",
    "    style_vec = normalize(embeddings.mean(axis=0).reshape(1, -1))[0]\n",
    "\n",
    "    summary = generate_llm_summary(posts, tone_vec, metadata)\n",
    "    print(\"\\nüìù Writing Style Summary:\\n\")\n",
    "    print(summary)\n",
    "\n",
    "    profile = {\n",
    "        \"user_id\": f\"user_{datetime.now().timestamp()}\",\n",
    "        \"created_at\": datetime.now().isoformat(),\n",
    "        **metadata,\n",
    "        \"tone_vector\": tone_vec,\n",
    "        \"tone_summary\": summary,\n",
    "        \"style_embedding\": style_vec.tolist(),\n",
    "        \"writing_samples\": posts\n",
    "    }\n",
    "\n",
    "    dataset_post = {\n",
    "        \"post_id\": str(uuid4()),\n",
    "        \"content\": \" \".join(posts),\n",
    "        \"platform\": metadata.get(\"platform\", \"unknown\"),\n",
    "        \"niche\": metadata.get(\"niche\", \"unknown\"),\n",
    "        \"archetypes\": metadata.get(\"archetypes\", []),\n",
    "        \"tone_summary\": summary,\n",
    "        \"style_embedding\": style_vec.tolist(),\n",
    "        \"tone_vector\": tone_vec\n",
    "    }\n",
    "\n",
    "    with open(\"dataset2_user_profiles.json\", \"a\") as f:\n",
    "        f.write(json.dumps(dataset_post) + \"\\n\")\n",
    "\n",
    "    print(\"\\nProfile and dataset2 record saved.\")\n",
    "    return summary \n",
    "\n",
    "def build_faiss_high_performing(csv_path):\n",
    "    df_perf = pd.read_csv(csv_path)\n",
    "\n",
    "    df_perf.columns = [\n",
    "        \"id\", \"content\", \"platform\", \"author_name\", \"source_link\", \"format\",\n",
    "        \"niche\", \"meta_niche\", \"audience_fit\", \"hook_type\", \"emotion_type\",\n",
    "        \"cta_style\", \"persuasion_type\", \"structure_type\", \"value_delivery_type\",\n",
    "        \"content_intent\", \"engagement_score\", \"engagement_bucket\"\n",
    "    ]\n",
    "\n",
    "    df_perf = df_perf[df_perf[\"engagement_bucket\"].str.strip() == \"Top 10%\"].reset_index(drop=True)\n",
    "\n",
    "    df_perf[\"combined_text\"] = df_perf[\"content\"].fillna(\"\") + \" [Niche: \" + df_perf[\"niche\"].fillna(\"\") + \"]\"\n",
    "\n",
    "    perf_texts = df_perf[\"combined_text\"].tolist()\n",
    "\n",
    "    perf_embeddings = encoder.encode(\n",
    "        perf_texts, convert_to_numpy=True, normalize_embeddings=True\n",
    "    ).astype('float32')\n",
    "\n",
    "    dim = perf_embeddings.shape[1]\n",
    "    faiss_index = faiss.IndexFlatL2(dim)\n",
    "    faiss_index.add(perf_embeddings)\n",
    "\n",
    "    return faiss_index, perf_texts, df_perf\n",
    " \n",
    "\n",
    "def search_relevant_content(query, user_niche, faiss_index, perf_texts, df_perf, top_n=5):\n",
    "    query_combined = f\"{query} [Niche: {user_niche}]\"\n",
    "    query_emb = encoder.encode([query_combined], convert_to_numpy=True, normalize_embeddings=True).astype('float32')  \n",
    "    \n",
    "    distances, indices = faiss_index.search(query_emb, top_n)\n",
    "\n",
    "    results = []\n",
    "    for idx, dist in zip(indices[0], distances[0]):\n",
    "        if idx < len(perf_texts):\n",
    "            post_row = df_perf.iloc[idx]\n",
    "            results.append({\n",
    "                \"similarity\": 1 - dist,  \n",
    "                \"content\": post_row['content'],\n",
    "                \"engagement_score\": post_row['engagement_score'],\n",
    "                \"niche\": post_row['niche'],\n",
    "                \"hook_type\": post_row['hook_type'],\n",
    "                \"emotion_type\": post_row['emotion_type']\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "def generate_custom_post(query, retrieved_contents, user_style_summary, platform=\"LinkedIn\"):\n",
    "    ref_posts = \"\\n\\n\".join([f\"- {text[:300]}\" for text in retrieved_contents])\n",
    "    prompt = f\"\"\"\n",
    "Task: Ensure the tone, lexicon, energy, and audience intent reflect the user's style. Write a brand new post for {platform} that resonates with the above style and the topic.\n",
    "Make sure the post is actionable, engaging, and appropriate for {platform}'s audience.\n",
    "Style: {user_style_summary}\n",
    "Topic: {query}\n",
    "Here are high-performing reference posts:\n",
    "{ref_posts}\n",
    "\"\"\"\n",
    "    response = gemini.generate_content(prompt)\n",
    "    return response.text.strip()\n",
    "\n",
    "def get_user_feedback(generated_post):\n",
    "    print(\"\\nüìù Generated Post:\\n\")\n",
    "    print(generated_post)\n",
    "    print(\"\\nWhat would you like to do with this post?\")\n",
    "    print(\"Options: accept / reject / modify_entirely / modify_partially\")\n",
    "\n",
    "    feedback = input(\"Your choice: \").strip().lower()\n",
    "    modified_post = \"\"\n",
    "\n",
    "    if feedback in [\"modify_entirely\", \"modify_partially\"]:\n",
    "        print(\"\\nPlease provide your modified version of the post below:\\n\")\n",
    "        modified_post = input(\"Modified Post:\\n\").strip()\n",
    "\n",
    "    return {\n",
    "        \"feedback\": feedback,\n",
    "        \"final_post\": modified_post if modified_post else generated_post\n",
    "    }\n",
    "\n",
    "def save_interaction_log(user_inputs):\n",
    "    log_filename = \"user_interaction_log.json\"\n",
    "    \n",
    "    with open(log_filename, \"a\") as f:\n",
    "        f.write(json.dumps(user_inputs) + \"\\n\")\n",
    "\n",
    "    print(f\"üìÅ Interaction saved to {log_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-30T19:15:07.790641Z",
     "iopub.status.busy": "2025-06-30T19:15:07.790036Z",
     "iopub.status.idle": "2025-06-30T19:16:32.675433Z",
     "shell.execute_reply": "2025-06-30T19:16:32.674662Z",
     "shell.execute_reply.started": "2025-06-30T19:15:07.790614Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94aa80fce3246bb823fb51deda3a673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Step 1: Provide your own posts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose Input Type:\n",
      "1. Paste Text\n",
      "2. Upload File\n",
      "3. Enter URL\n",
      "4. Use Infographic Image (from dataset)\n",
      "5. Use Audio Clip (from dataset)\n",
      "Enter choice (1-5):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using image from Kaggle input dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter full image path (e.g., /kaggle/input/your-dataset-name/infographic.png):  /kaggle/input/image-test/ocr1.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Extracted Text from Image:\n",
      "--------------------------------------------------\n",
      "Find the right person for company. Fast: Linkedln Jobs can help you: Target the most Screen for qualified Review andrate the relevant candidates: applicants: best matches: Linkedl-UC dato anqinsinntsto pictutt opplicant; Filtrr andtalcyour applicznts Mmach %Nur ciitorio ith norson'& sxills, quclihcnticns with Gssessment tocls like FOCe Kussd Ihs 0n3s you considar Gtocrrnco gncl; putlina your jnb scrocting 7unsticns Gnd,kill Onco Unkccln #iiccommcno ont cuelovonimmche M mke Ossassmstis ycurjob post 10 Ceadia cajicnjotioM apply How to post job on Linkedln: KaKeTh [ent Ma Wtt| Cutenet Asnneaan *arnhen 915 100 Start from the Jcbs poge Set your budgel Post und mancge Youi eos allin one place; Hgatfiom Ater \"cupost Yullco j0iues Vcu ccn cnuoge dally thc: Linkudln Jobx puge total buudlgel uromnote Yout Fosl wvill aulomalically Laue\"ten v0uvereachedvou: lola_buudel ndna Le Pian Mota Iet KiEFit Eit5 Etis FieEtct Juntodt M Men Ootald # Ote # MittLetta Lanmtn Veedn Hnenaahtd Keetelodd # Targot tharightpoopla; Roviovrate nndtcnchout Tell us wrho vou're looking iot, and vie cun get vourjon Eosily reviel ond pnortize condidates cnboth desktop ond Joncchamestqualinedcndidateawho mcitch Tcbileuth Gi simple hkenng cnd manacement tools vour needsund are ie mcst Ike]~ dpply. Rate the ones You le and (edch outto gan Convergation your\n",
      "--------------------------------------------------\n",
      "\n",
      "üéØ Cognitive Framing:\n",
      "A: I like to simplify complexity so people get the ‚Äòaha!‚Äô moment.\n",
      "B: I like to explore nuanced topics, even if they‚Äôre a bit messy or open-ended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose A or B:  A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Value Communication:\n",
      "A: I try to give readers something they can immediately apply.\n",
      "B: I aim to change how readers think about a topic.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose A or B:  A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Emotional Tone:\n",
      "A: I prefer to keep a calm, composed tone in my content.\n",
      "B: I‚Äôm okay showing strong opinions and emotional highs/lows.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose A or B:  A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Communication Texture:\n",
      "A: I speak in plain, precise language.\n",
      "B: I enjoy using analogies, metaphors, or playful phrasing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose A or B:  A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Risk Appetite:\n",
      "A: I prefer to play it safe ‚Äî stay useful, stay relevant.\n",
      "B: I‚Äôm okay challenging norms or triggering strong reactions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose A or B:  A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Relational Energy:\n",
      "A: I tend to speak to the audience like a guide or coach.\n",
      "B: I like writing more like a peer, friend, or co-explorer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose A or B:  A\n",
      "\n",
      "What niche do you create content in?  AI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select 1‚Äì2 primary content goals:\n",
      "1. reach\n",
      "2. sales\n",
      "3. trust\n",
      "4. educate\n",
      "5. thought leadership\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter goal numbers (comma-separated):  1,2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Select 1‚Äì2 content archetypes:\n",
      "1. The Teacher\n",
      "2. The Challenger\n",
      "3. The Storyteller\n",
      "4. The Visionary\n",
      "5. The Operator\n",
      "6. The Curator\n",
      "7. The Trend Decoder\n",
      "8. The Builder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter archetype numbers:  1\n",
      "\n",
      " Primary platform (LinkedIn, Instagram, etc):  LinkedIn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f022b79a6f70434ba27ff54758a66e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Writing Style Summary:\n",
      "\n",
      "Based on the provided text snippet (\"Find the right person for company. Fast: Linkedln Jobs can help you: Target the most Screen for qual\"), the creator's writing style can be summarized as follows:\n",
      "\n",
      "* **Cognitive Style:** Logic-driven. The writing is concise and focuses on presenting facts and solutions (using LinkedIn Jobs).  There's no room for intuition or subjective opinions.\n",
      "\n",
      "* **Energy Signature:**  Aggressive (in a business sense). The words \"Fast\" and the implied urgency suggest a direct, results-oriented approach.  It's not calm or witty; it's focused on efficiency.\n",
      "\n",
      "* **Lexical Patterns:** The writing is telegraphic, using short sentences and minimal punctuation.  Word choice is functional rather than expressive.  There's a noticeable lack of complete sentences and grammatical correctness (e.g., \"Screen for qual\").  This suggests a fast-paced, possibly rushed style.\n",
      "\n",
      "* **Narrative Identity:** Guide/Expert. The post implies the creator possesses the knowledge to help users find the right people quickly, positioning them as a knowledgeable guide.\n",
      "\n",
      "* **Content Archetype:** Aligns with the provided 'The Teacher' archetype. The post offers a solution (LinkedIn Jobs) to a problem (finding the right person).  It's instructional, though minimally so due to the brevity.\n",
      "\n",
      "* **Audience Intent:** Recruiters/Businesses. The post is directly targeted at those seeking to fill job openings quickly.\n",
      "\n",
      "\n",
      "**How they frame ideas and close posts:**\n",
      "\n",
      "The creator frames ideas directly and concisely, focusing on the problem and presenting the solution immediately.  The post doesn't have a formal closing; it abruptly ends, reinforcing the sense of urgency and efficiency.  The incomplete sentence (\"Screen for qual\") further emphasizes this rushed, business-focused approach.  This style prioritizes actionable information over lengthy explanations or persuasive narratives.  The brevity suggests a \"here's the solution, use it\" mentality.\n",
      "\n",
      "Profile and dataset2 record saved.\n",
      "\n",
      "‚úÖ FAISS index loaded. Ready for topic generation.\n",
      "\n",
      "üß† Step 2: Provide your post topic (text, voice, URL, etc.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose Input Type:\n",
      "1. Paste Text\n",
      "2. Upload File\n",
      "3. Enter URL\n",
      "4. Use Infographic Image (from dataset)\n",
      "5. Use Audio Clip (from dataset)\n",
      "Enter choice (1-5):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Provide 1 Topic/Idea for Your New Post:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 1:  job recruitement\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871e2ca34cf5400b9e00594e65ca2250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Top relevant posts:\n",
      "\n",
      "1. Similarity: 0.215 | Engagement Score: 9214\n",
      "    Niche: AI | Hook: Relatable Statement | Emotion: Empathy\n",
      "    ‚Üí AI has changed job hunting forever. Use the right tools to accelerate your career. Land your dream job today. Use the Ultimate ChatGPT Guide for job hunting. Forget the painful job application process. Make things easier and steal this guide: 1) Critical AI Application Tools - Practice real-life job...\n",
      "--------------------------------------------------------------------------------\n",
      "2. Similarity: 0.149 | Engagement Score: 866\n",
      "    Niche: AI | Hook: Relatable Statement | Emotion: Inspiration\n",
      "    ‚Üí Job opportunity: Business Manager at 20-30 LPA, for a startup building the #1 tech talent network on the planet. Be part of a company: ‚ûù That has grown to Rs 22 crores (~$3 million) in revenues ‚ûù Will grow to $10 million by next year ‚ûù With 100,000+ software engineers in our talent network An ideal ...\n",
      "--------------------------------------------------------------------------------\n",
      "3. Similarity: 0.142 | Engagement Score: 462\n",
      "    Niche: AI | Hook: Relatable Statement | Emotion: Inspiration\n",
      "    ‚Üí If you‚Äôre brainstorming about how to drive growth without talking to *actual customers*... You‚Äôre doing it wrong\n",
      "--------------------------------------------------------------------------------\n",
      "4. Similarity: 0.122 | Engagement Score: 1203\n",
      "    Niche: AI | Hook: Relatable Statement | Emotion: Inspiration\n",
      "    ‚Üí I can point every good result in my life back to this simple daily habit:\n",
      "--------------------------------------------------------------------------------\n",
      "5. Similarity: 0.105 | Engagement Score: 900\n",
      "    Niche: AI | Hook: Relatable Statement | Emotion: Curiosity\n",
      "    ‚Üí In an AI future, marketing departments will be engineer-led‚Äîthe CMO? Likely an engineer. GenAI is going to rewrite how we do marketing. Marketing will look more like - Prompts replace briefs - AI models curate content drafts, humans edit - Train AI on brand voice. Code drives campaigns - Humans to d...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Generated Post:\n",
      "\n",
      "Stop wasting time. Find top talent. Now.\n",
      "\n",
      "LinkedIn Recruiter.  Target. Filter. Hire.\n",
      "\n",
      "Optimize your search.  Maximize results.  \n",
      "\n",
      "Get started: [Link to LinkedIn Recruiter]\n",
      "\n",
      "üìù Generated Post:\n",
      "\n",
      "Stop wasting time. Find top talent. Now.\n",
      "\n",
      "LinkedIn Recruiter.  Target. Filter. Hire.\n",
      "\n",
      "Optimize your search.  Maximize results.  \n",
      "\n",
      "Get started: [Link to LinkedIn Recruiter]\n",
      "\n",
      "What would you like to do with this post?\n",
      "Options: accept / reject / modify_entirely / modify_partially\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your choice:  accept\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Interaction saved to user_interaction_log.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    CSV_PATH = \"/kaggle/input/highest/dataset2_combined_output.csv\"\n",
    "    faiss_high_perf, high_perf_texts, df_perf = build_faiss_high_performing(CSV_PATH)\n",
    "\n",
    "    print(\"\\n Step 1: Provide your own posts\")\n",
    "    user_posts, _ = get_user_inputs(mode=\"profile\")\n",
    "\n",
    "    if len(user_posts) < 1:\n",
    "        print(\"\\n‚ö†Ô∏è Not enough content samples. Please restart and try again.\")\n",
    "        exit()\n",
    "\n",
    "    tone_vector = get_tone_vector()\n",
    "    user_meta = get_user_metadata()\n",
    "    user_style_summary = build_psyprint_dataset(user_posts, tone_vector, user_meta)\n",
    "    print(\"\\n‚úÖ FAISS index loaded. Ready for topic generation.\")\n",
    "\n",
    "    print(\"\\nüß† Step 2: Provide your post topic (text, voice, URL, etc.)\")\n",
    "    topic_inputs, _ = get_user_inputs(mode=\"topic\")\n",
    "\n",
    "    if not topic_inputs:\n",
    "        print(\"\\n‚ö†Ô∏è No topic provided. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    query = topic_inputs[0]\n",
    "    user_niche = user_meta[\"niche\"]\n",
    "\n",
    "    matches = search_relevant_content(query, user_niche, faiss_high_perf, high_perf_texts, df_perf, top_n=5)\n",
    "\n",
    "    print(\"\\nüìå Top relevant posts:\\n\")\n",
    "    for i, res in enumerate(matches, 1):\n",
    "        print(f\"{i}. Similarity: {res['similarity']:.3f} | Engagement Score: {res['engagement_score']}\")\n",
    "        print(f\"    Niche: {res['niche']} | Hook: {res['hook_type']} | Emotion: {res['emotion_type']}\")\n",
    "        print(f\"    ‚Üí {res['content'][:300]}{'...' if len(res['content']) > 300 else ''}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    retrieved_texts = [res['content'] for res in matches]\n",
    "    generated_post = generate_custom_post(query, retrieved_texts, user_style_summary, user_meta['platform'])\n",
    "\n",
    "    print(\"\\nüìù Generated Post:\\n\")\n",
    "    print(generated_post)\n",
    "\n",
    "    feedback_data = get_user_feedback(generated_post)\n",
    "\n",
    "    interaction_log = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"query\": query,\n",
    "        \"user_meta\": user_meta,\n",
    "        \"platform\": user_meta['platform'],\n",
    "        \"tone_vector\": tone_vector,\n",
    "        \"user_style_summary\": user_style_summary,\n",
    "        \"retrieved_reference_posts\": retrieved_texts,\n",
    "        \"generated_post\": generated_post,\n",
    "        \"feedback\": feedback_data['feedback'],\n",
    "        \"final_post\": feedback_data['final_post']\n",
    "    }\n",
    "\n",
    "    save_interaction_log(interaction_log)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7687244,
     "sourceId": 12203503,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7767400,
     "sourceId": 12322623,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7772971,
     "sourceId": 12330758,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
